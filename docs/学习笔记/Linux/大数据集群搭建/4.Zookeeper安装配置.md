# 解压改名
```sh
tar -xzvf /opt/software/zookeeper-3.4.5.tar.gz -C /opt/modules/

mv /opt/modules/zookeeper-3.4.5/ /opt/modules/zookeeper-standalone
```
zookeeper具有[单机模式](#1单机模式standalone)和[集群模式](#2集群模式)

# 1、单机模式(standalone)
在zookeeper-standalone目录下新建data和logs目录(data目录用来存放数据库快照，logs目录用来存放日志文件)
```sh
mkdir data && mkdir logs
```

进入zookeeper-standalone目录下的 conf 配置文件夹

复制cp zoo_sample.cfg 文件改名为zoo.cfg，命令如下：
```sh
cp zoo_sample.cfg zoo.cfg
```
使用vi命令修改zoo.cfg配置文件,修改内容如下：
```sh
# zookeeper-standalone 保存数据的数据库快照的位置
dataDir=/opt/modules/zookeeper-standalone/data
# 事务日志日志路径
dataLogDir=/opt/modules/zookeeper-standalone/logs
```
dataDir 默认存在，修改路径即可，dataLogDir 不存在，需要手动添加

配置完之后就可以直接启动zookeeper。
```sh
cd /opt/modules/zookeeper-standalone/bin #进入启动目录
./zkServer.sh start # 执行启动命令
```
```sh
[root@master bin]# ./zkServer.sh start
JMX enabled by default
Using config: /opt/modules/zookeeper-standalone/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED
```
启动成功

可以使用 status 命令查看zookeeper状态
```sh
[root@master bin]# ./zkServer.sh status
JMX enabled by default
Using config: /opt/modules/zookeeper-standalone/bin/../conf/zoo.cfg
Mode: standalone
```

# 2、集群模式
与单机模式同样的方法，先在zookeeper目录下新建data和logs目录，复制zoo_sample.cfg文件改名为zoo.cfg
```
mkdir data && mkdir logs
```

使用vi命令修改配置文件zoo.cfg

修改内容如下：
```sh
# zookeeper-standalone 保存数据的数据库快照的位置
dataDir=/opt/modules/zookeeper/data
# 事务日志日志路径
dataLogDir=/opt/modules/zookeeper/logs

#在文件底部添加server
server.1=192.168.80.10:2888:3888
server.2=192.168.80.11:2888:3888
server.3=192.168.80.12:2888:3888
```
说明： server.n n是一个数字，表示这个是第几号服务器，“=”后面可跟主机地址或者IP地址，2888为集群中从服务器（follower）连接到主服务器（leader）的端口，为主服务器（leader）使用；3888为进行选举（leader）的时使用的端口

使用vi命令在data目录下面新建一个myid文件，将刚才添加代码里面server.n的n写入myid文件里面，只写入数字。
```sh
[root@master zookeeper]# vi /opt/modules/zookeeper/data/myid

1
~                                                                   
~                                                                                                            
~                                                                          
"myid" [New File]   
```
将配置好了的zookeeper文件传给另外两台服务器
```sh
scp -r /opt/modules/zookeeper root@slave1:/opt/modules/
scp -r /opt/modules/zookeeper root@slave2:/opt/modules/
```
分别修改 slave1和slave2中的myid的数为2和3
```sh
[root@slave1 zookeeper]# vi /opt/modules/zookeeper/data/myid

2
~                                                            
~                                                                                
~                                                                          
"myid" [File] 
```
```sh
[root@slave2 zookeeper]# vi /opt/modules/zookeeper/data/myid

3
~                                                                   
~                                                                            
~                                                                          
"myid" [File] 
```
关闭防火墙

关闭防火墙

关闭防火墙

重要的事说三遍，防火墙很重要，非常重要，如果没有关闭防火墙，很有可能导致启动不成功。

如果按照我的Hadoop安装的时候关闭过了就可以跳过这步

## 首先启动master主服务器上面的zookeeper，其次slave1和slave2
```sh
master:
[root@master ~]# cd /opt/modules/zookeeper/bin
[root@master bin]# ./zkServer.sh start
ZooKeeper JMX enabled by default
Using config: /opt/modules/zookeeper/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED

slave1:
[root@slave1 ~]# cd /opt/modules/zookeeper/bin
[root@slave1 bin]# ./zkServer.sh start
ZooKeeper JMX enabled by default
Using config: /opt/modules/zookeeper/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED

slave2:
[root@slave2 ~]# cd /opt/modules/zookeeper/bin
[root@slave2 bin]# ./zkServer.sh start
ZooKeeper JMX enabled by default
Using config: /opt/modules/zookeeper/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED
```
## 最后分别查看每台机器的status
```sh
master:
[root@master bin]# ./zkServer.sh status
JMX enabled by default
Using config: /opt/modules/zookeeper/bin/../conf/zoo.cfg
Mode: leader

slave1:
[root@slave1 bin]# ./zkServer.sh status
JMX enabled by default
Using config: /opt/modules/zookeeper/bin/../conf/zoo.cfg
Mode: follower

slave2:
[root@slave2 bin]# ./zkServer.sh status
JMX enabled by default
Using config: /opt/modules/zookeeper/bin/../conf/zoo.cfg
Mode: follower
```

# 在ZooKeeper集群中的角色分配说明

- Leader（领导者）：每个ZooKeeper集群中只有一个Leader角色。Leader负责处理所有的客户端请求，并协调集群中的各个节点。它负责写操作的原子广播和读操作的快速响应。

- Follower（跟随者）：Follower是ZooKeeper集群中的普通节点，它们负责接收客户端请求并将其转发给Leader。Follower参与写操作的投票，并在Leader选举中参与投票。

- Observer（观察者）：Observer是一种特殊类型的节点，它类似于Follower，但不参与写操作的投票。Observer节点可以在不增加集群写负载的情况下提供更好的读取性能。Observer节点可以通过复制Leader节点的数据来提供读取服务。

- 角色分配是通过选举过程来确定的。当ZooKeeper集群启动或Leader节点失效时，集群中的节点将参与选举过程，以确定新的Leader。选举过程中，节点会相互通信，进行投票，并根据选票数来决定新的Leader角色。

- 需要注意的是，ZooKeeper集群中的节点数量应该是奇数，以确保选举过程的正确性和容错性。通常建议至少有3个节点组成一个ZooKeeper集群，以保证高可用性和容错性。

# 后面看个人需求配置环境变量后可以在任意地方使用 zkServer.sh start 来启动集群