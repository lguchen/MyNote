## 修改配置文件server.properties
```javascript
listeners=PLAINTEXT://master:9092
broker.id=0
zookeeper.connect=master,slave1,slave2
```
## 将kafka发送到其他节点
```
scp -r kafka/ slave1:/home
scp -r kafka/ slave2:/home
```
## 在server.properties上修改broker.id分别为1和2
```
broker.id=1   //slave1
listeners=PLAINTEXT://slave1:9092

broker.id=2    //slave2
listeners=PLAINTEXT://slave2:9092
```
## 启动kafka之前在各个节点上启动zookeeper
`zkServer.sh start`

## 在各节点上启动kafka服务

```bash
./bin/kafka-server-start.sh ../config/server.properties
```
## 在flume写配置文件vi flume_mem_kafka.conf
```bash
agent1.sources=src
agent1.channels=ch
agent1.sinks=des_kafka

agent1.sources.src.type=spooldir
agent1.sources.src.spoolDir=/home/hadoop/data

agent1.channels.ch.type=memory

agent1.sinks.des_kafka.type=org.apache.flume.sink.kafka.KafkaSink
agent1.sinks.des_kafka.brokerList=master:9092,slave1:9092,slave2:9092
agent1.sinks.des_kafka.topic=wordsendertest

agent1.sources.src.channels=ch
agent1.sinks.des_kafka.channel=ch
```
## 在master创建topic  生产者

```bash
./bin/kafka-topic.sh --create --zookeeper master:2181,slave1:2181,slave2:2181 --replication-factor 2 --topic word --partitions 1

./bin/kafka-console-producer.sh --broker-list master:9092,slave1:9092,slave2:9092 --topic word
```
## 在salve1上创建消费者
```bash
kafka/bin/kafka-console-consumer.sh --bootstrap-server master:9092,slave1:9092,slave2:9092 --topic word--from-beginning
```
## 启动flume
```bash
cd  /opt/module/flume/conf/
flume-ng agent –c . –f flume_mem_kafka.conf –n agent1 –Dflume.root.logger=DEBUG,console
```